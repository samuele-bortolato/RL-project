{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37385503",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-10T09:23:14.691950Z",
     "iopub.status.busy": "2023-07-10T09:23:14.691559Z",
     "iopub.status.idle": "2023-07-10T09:23:14.708414Z",
     "shell.execute_reply": "2023-07-10T09:23:14.707472Z"
    },
    "papermill": {
     "duration": 0.02281,
     "end_time": "2023-07-10T09:23:14.710468",
     "exception": false,
     "start_time": "2023-07-10T09:23:14.687658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.listdir('../input/rl-project')\n",
    "# import sys\n",
    "# sys.path.insert(0,'../input/rl-project/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4813075",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T09:23:14.716189Z",
     "iopub.status.busy": "2023-07-10T09:23:14.715915Z",
     "iopub.status.idle": "2023-07-10T09:23:25.736401Z",
     "shell.execute_reply": "2023-07-10T09:23:25.735363Z"
    },
    "papermill": {
     "duration": 11.026327,
     "end_time": "2023-07-10T09:23:25.739069",
     "exception": false,
     "start_time": "2023-07-10T09:23:14.712742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions import Categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import time\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import socket\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from agents import Agent\n",
    "from environment import SimulationEnvironment0\n",
    "from replay_buffers import *\n",
    "from utils import *\n",
    "\n",
    "import copy\n",
    "experiment_name='discrete_control_PPO_buffers1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3b31615",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T09:23:25.745916Z",
     "iopub.status.busy": "2023-07-10T09:23:25.745252Z",
     "iopub.status.idle": "2023-07-10T11:03:02.450685Z",
     "shell.execute_reply": "2023-07-10T11:03:02.444002Z"
    },
    "papermill": {
     "duration": 5976.7111,
     "end_time": "2023-07-10T11:03:02.452597",
     "exception": true,
     "start_time": "2023-07-10T09:23:25.741497",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/131072 [00:19<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 138\u001b[0m\n\u001b[0;32m    136\u001b[0m dist \u001b[39m=\u001b[39m Categorical(action_probs)\n\u001b[0;32m    137\u001b[0m sampled_action \u001b[39m=\u001b[39m dist\u001b[39m.\u001b[39msample()\n\u001b[1;32m--> 138\u001b[0m log_prob \u001b[39m=\u001b[39m dist\u001b[39m.\u001b[39mlog_prob(sampled_action)\n\u001b[0;32m    140\u001b[0m u, v \u001b[39m=\u001b[39m dec_x[sampled_action], dec_y[sampled_action]\n\u001b[0;32m    141\u001b[0m sampled_action_decoded \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([u,v],\u001b[39m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 138\u001b[0m\n\u001b[0;32m    136\u001b[0m dist \u001b[39m=\u001b[39m Categorical(action_probs)\n\u001b[0;32m    137\u001b[0m sampled_action \u001b[39m=\u001b[39m dist\u001b[39m.\u001b[39msample()\n\u001b[1;32m--> 138\u001b[0m log_prob \u001b[39m=\u001b[39m dist\u001b[39m.\u001b[39mlog_prob(sampled_action)\n\u001b[0;32m    140\u001b[0m u, v \u001b[39m=\u001b[39m dec_x[sampled_action], dec_y[sampled_action]\n\u001b[0;32m    141\u001b[0m sampled_action_decoded \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([u,v],\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1395\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1344\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Sam\\miniconda3\\envs\\torch\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Sam\\miniconda3\\envs\\torch\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[0;32m   2108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed = 0\n",
    "\n",
    "EXPERIMENTS = [#{\"entropy\": 3e-4, 'epochs':0, 'PPO':1, 'training_steps':2**17, 'size': 2**16},\n",
    "               #{\"entropy\": 3e-4, 'epochs':0, 'PPO':2, 'training_steps':2**17, 'size': 2**16},\n",
    "               #{\"entropy\": 3e-4, 'epochs':1, 'PPO':1, 'training_steps':2**17, 'size': 2**16},\n",
    "               #{\"entropy\": 3e-4, 'epochs':1, 'PPO':2, 'training_steps':2**17, 'size': 2**16},\n",
    "               #{\"entropy\": 3e-4, 'epochs':2, 'PPO':1, 'training_steps':2**17, 'size': 2**16},\n",
    "               #{\"entropy\": 3e-4, 'epochs':2, 'PPO':2, 'training_steps':2**17, 'size': 2**16},\n",
    "               #{\"entropy\": 3e-4, 'epochs':2, 'PPO':2, 'training_steps':2**17, 'size': 2**16},\n",
    "               #{\"entropy\": 3e-4, 'epochs':0, 'PPO':4, 'training_steps':2**17, 'size': 2**16},\n",
    "               #{\"entropy\": 3e-4, 'epochs':1, 'PPO':4, 'training_steps':2**17, 'size': 2**16},\n",
    "               #{\"entropy\": 3e-4, 'epochs':2, 'PPO':4, 'training_steps':2**17, 'size': 2**16},\n",
    "               {\"entropy\": 3e-4, 'epochs':0, 'PPO':1, 'training_steps':2**17, 'size': 2**12},\n",
    "               {\"entropy\": 3e-4, 'epochs':0, 'PPO':2, 'training_steps':2**17, 'size': 2**12},\n",
    "               {\"entropy\": 3e-4, 'epochs':0, 'PPO':4, 'training_steps':2**17, 'size': 2**12},\n",
    "               {\"entropy\": 3e-4, 'epochs':1, 'PPO':1, 'training_steps':2**17, 'size': 2**12},\n",
    "               {\"entropy\": 3e-4, 'epochs':1, 'PPO':2, 'training_steps':2**17, 'size': 2**12},\n",
    "               {\"entropy\": 3e-4, 'epochs':1, 'PPO':4, 'training_steps':2**17, 'size': 2**12},\n",
    "               {\"entropy\": 3e-4, 'epochs':2, 'PPO':1, 'training_steps':2**17, 'size': 2**12},\n",
    "               {\"entropy\": 3e-4, 'epochs':2, 'PPO':2, 'training_steps':2**17, 'size': 2**12},\n",
    "               {\"entropy\": 3e-4, 'epochs':2, 'PPO':4, 'training_steps':2**17, 'size': 2**12},\n",
    "               ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# simulation\n",
    "num_simulations = 128\n",
    "num_blackholes = 1\n",
    "\n",
    "# agent\n",
    "hidden_size = 512\n",
    "simlog_res = 255\n",
    "use_symlog = True\n",
    "simlog_half_res = simlog_res//2\n",
    "simlog_max_range = 1\n",
    "actions_res = 5\n",
    "levels=2\n",
    "input_type = 'complete'\n",
    "\n",
    "lr = 3e-4\n",
    "lr_actor = 3e-5\n",
    "\n",
    "\n",
    "# training\n",
    "#training_steps = 2**18\n",
    "#epochs=8\n",
    "gamma = 0.98\n",
    "smoothing = 1e-2\n",
    "eps = 0.1\n",
    "\n",
    "batch_size = 2**10\n",
    "\n",
    "# replay buffers\n",
    "buffer = Replay_Buffer\n",
    "#size = 2**16\n",
    "batch_size = 2**10\n",
    "\n",
    "plot = False\n",
    "\n",
    "validate_every = 2**7\n",
    "\n",
    "bin_values = (torch.arange(simlog_res)-simlog_half_res).cuda()/simlog_half_res*simlog_max_range\n",
    "bin_values = bin_values.sign()*(bin_values.abs().exp()-1)\n",
    "\n",
    "dec_x, dec_y = torch.meshgrid(torch.arange(actions_res)/(actions_res-1)*2-1, torch.arange(actions_res)/(actions_res-1)*2-1)\n",
    "dec_x, dec_y = dec_x.flatten().cuda(), dec_y.flatten().cuda()\n",
    "\n",
    "metric_idx = torch.pow(2,torch.arange(15))-1\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "\n",
    "for experiment in EXPERIMENTS:\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    current_time = datetime.now().strftime(\"%b%d_%H-%M-%S\")\n",
    "    log_dir = os.path.join(\n",
    "        \"runs\",experiment_name, current_time + \"_\" + socket.gethostname() \n",
    "    )\n",
    "\n",
    "    tb_writer = SummaryWriter(log_dir)\n",
    "\n",
    "    sim = SimulationEnvironment0(num_simulations=128,\n",
    "                            num_blackholes=num_blackholes, \n",
    "                            force_constant=0.002, \n",
    "                            velocity_scale=0.01,\n",
    "                            goal_threshold=0.05,\n",
    "                            max_steps=250,\n",
    "                            device='cuda')\n",
    "\n",
    "    if use_symlog:\n",
    "        actor = Agent((num_blackholes+2), hidden_size, levels, input_type, critic=False, action_dimension=actions_res**2).cuda()\n",
    "        critic = Agent((num_blackholes+2), hidden_size, levels, input_type, actor=False, value_dimension=simlog_res).cuda()\n",
    "    else:\n",
    "        actor = Agent((num_blackholes+2), hidden_size, levels, input_type, critic=False, action_dimension=actions_res**2).cuda()\n",
    "        critic = Agent((num_blackholes+2), hidden_size, levels, input_type, actor=False, value_dimension=1).cuda()\n",
    "\n",
    "    optim_actor = torch.optim.AdamW(actor.parameters(), lr=lr_actor, weight_decay=1e-3)\n",
    "    optim_critic = torch.optim.AdamW(critic.parameters(), lr=lr, weight_decay=1e-3)\n",
    "    target_critic = copy.deepcopy(critic)\n",
    "    \n",
    "    replay_buffer = buffer(state_shape=((num_blackholes+2),2), action_shape=(1,), batch_size=batch_size, size=experiment['size'], device='cuda')\n",
    "\n",
    "    old_states=None\n",
    "\n",
    "    R=[]\n",
    "\n",
    "    from tqdm import tqdm\n",
    "    pbar = tqdm(range(experiment['training_steps']))\n",
    "\n",
    "    x,y = torch.meshgrid(torch.arange(100),torch.arange(100))\n",
    "    pos = torch.stack([x.flatten(), y.flatten()],1)/100\n",
    "    target_pos = torch.ones_like(pos)*0.25\n",
    "    bh_pos = torch.ones_like(pos)*0.75\n",
    "\n",
    "    st=torch.stack([pos,target_pos,bh_pos],1)\n",
    "\n",
    "    E = []\n",
    "    plotV = []\n",
    "    plotVT = []\n",
    "    plotPolicy = []\n",
    "\n",
    "    \n",
    "    states = sim.get_state()\n",
    "    for i in pbar:\n",
    "        t0=time.time()\n",
    "\n",
    "        # generate experience\n",
    "        states = states.reshape(states.shape[0],-1).cuda()\n",
    "        actions, _ = actor(states)\n",
    "        _, values = critic(states)\n",
    "\n",
    "        action_probs = actions.softmax(-1)\n",
    "        dist = Categorical(action_probs)\n",
    "        sampled_action = dist.sample()\n",
    "        log_prob = dist.log_prob(sampled_action)\n",
    "\n",
    "        u, v = dec_x[sampled_action], dec_y[sampled_action]\n",
    "        sampled_action_decoded = torch.stack([u,v],1)\n",
    "\n",
    "        rewards, new_states, is_terminal = sim.step(sampled_action_decoded)\n",
    "\n",
    "        # train the critic\n",
    "        with torch.inference_mode():\n",
    "            _, next_values = target_critic(new_states.reshape(new_states.shape[0],-1).cuda())\n",
    "\n",
    "            if use_symlog:\n",
    "                expexted_next_value = (torch.softmax(next_values,1)@bin_values[:,None])[:,0]*(is_terminal.logical_not())\n",
    "            else:\n",
    "                expexted_next_value = next_values.squeeze(1)*(is_terminal.logical_not())\n",
    "\n",
    "            expecter_target_value = rewards + gamma*expexted_next_value\n",
    "\n",
    "        if use_symlog:\n",
    "            y = two_hot_encode(expecter_target_value, simlog_max_range, simlog_res, simlog_half_res, smoothing=smoothing)\n",
    "            critic_error = torch.nn.functional.cross_entropy(values, y, reduction='none')\n",
    "        else:\n",
    "            critic_error = torch.square(values-expecter_target_value)\n",
    "\n",
    "        optim_critic.zero_grad()\n",
    "        critic_error.mean().backward()\n",
    "        optim_critic.step()\n",
    "\n",
    "        # train the actor\n",
    "        expexted_value = (torch.softmax(values,1)@bin_values[:,None])[:,0]\n",
    "        expected_prediction_error = (expexted_value - expecter_target_value)\n",
    "\n",
    "        H = -(action_probs*(action_probs+1e-8).log()).sum(-1)\n",
    "        actor_error = expected_prediction_error.detach() * log_prob - H*experiment['entropy']\n",
    "\n",
    "        optim_actor.zero_grad()\n",
    "        actor_error.mean().backward()\n",
    "        optim_actor.step()\n",
    "\n",
    "\n",
    "        if isinstance(replay_buffer, Replay_Buffer):\n",
    "            replay_buffer.add_experience(states=states, actions=sampled_action, action_probs=log_prob, rewards=rewards, next_states=new_states, terminals=is_terminal)\n",
    "        elif isinstance(replay_buffer, Prioritized_Replay_Buffer):\n",
    "            replay_buffer.add_experience(states=states, actions=sampled_action, action_probs=log_prob, rewards=rewards, next_states=new_states, terminals=is_terminal, weights=critic_error+1e-7)\n",
    "\n",
    "        #log\n",
    "        E.append(critic_error.mean().item())\n",
    "        R.append(rewards.mean().item())\n",
    "\n",
    "        tb_writer.add_scalar('TD error', expected_prediction_error.mean().item(), i)\n",
    "        tb_writer.add_scalar('Actor error', actor_error.mean().item(), i)\n",
    "        tb_writer.add_scalar('Critic error', critic_error.mean().item(), i)\n",
    "        tb_writer.add_scalar('Reward',rewards.mean().item(), i)\n",
    "\n",
    "        # train actor with PPO\n",
    "        old_probs = log_prob.exp().detach()\n",
    "        for b_idx in range(experiment['PPO']):\n",
    "\n",
    "            actions, _ = actor(states)\n",
    "\n",
    "            action_probs = actions.softmax(-1)\n",
    "            H = -(action_probs*(action_probs+1e-8).log()).sum(-1)\n",
    "            dist = Categorical(action_probs)\n",
    "            log_prob = dist.log_prob(sampled_action)\n",
    "\n",
    "            r = log_prob.exp()/(old_probs+1e-8)\n",
    "            objective = expected_prediction_error.detach() * r #inverse, to me minimized\n",
    "            objective_clipped =  expected_prediction_error.detach() * r.clip(1-eps,1+eps)\n",
    "\n",
    "            actor_error = torch.maximum(objective,objective_clipped) - H*experiment['entropy']\n",
    "\n",
    "            optim_actor.zero_grad()\n",
    "            actor_error.mean().backward()\n",
    "            optim_actor.step()\n",
    "\n",
    "        # train critic on old experience\n",
    "        for b_idx in range(experiment['epochs']):\n",
    "            b_states, b_actions, b_log_prob, b_rewards, b_next_states, b_terminals, weights = replay_buffer.get_batch()\n",
    "\n",
    "            _, values = critic(b_states.reshape(b_states.shape[0],-1).cuda())\n",
    "\n",
    "            with torch.inference_mode():\n",
    "                _, next_values = target_critic(b_next_states.reshape(b_next_states.shape[0],-1).cuda())\n",
    "\n",
    "                expexted_next_value = (torch.softmax(next_values,1)@bin_values[:,None])[:,0]*(b_terminals.logical_not())\n",
    "\n",
    "                expecter_target_value = b_rewards + gamma*expexted_next_value\n",
    "\n",
    "            y = two_hot_encode(expecter_target_value, simlog_max_range, simlog_res, simlog_half_res, smoothing=smoothing)\n",
    "            critic_error = (torch.nn.functional.cross_entropy(values, y, reduction='none'))\n",
    "\n",
    "            expexted_value = (torch.softmax(values,1)@bin_values[:,None])[:,0]\n",
    "            expected_prediction_error = (expexted_value - expecter_target_value)\n",
    "\n",
    "            if weights is not None:\n",
    "                critic_error /= weights\n",
    "\n",
    "            optim_critic.zero_grad()\n",
    "            critic_error.mean().backward()\n",
    "            optim_critic.step()\n",
    "\n",
    "            if weights is not None:\n",
    "                replay_buffer.update_weights(critic_error+1e-7)\n",
    "\n",
    "        update_target_model(model=critic, target_model=target_critic, decay=1e-3)\n",
    "\n",
    "        states = new_states\n",
    "\n",
    "        if i % 8 == 0:\n",
    "            pbar.set_postfix_str(f'{critic_error.mean().item():.3g}'.ljust(10)+\n",
    "                                 f'{actor_error.mean().item():.3g}'.ljust(10)+\n",
    "                                f'{rewards.mean().item():.3g}'.ljust(10))\n",
    "\n",
    "\n",
    "        if (i+1) % validate_every == 0:\n",
    "\n",
    "            V = []\n",
    "            A = []\n",
    "            for b in range((len(st)+batch_size-1)//batch_size):\n",
    "                stb = st[b*batch_size:(b+1)*batch_size]\n",
    "                _, v = critic(stb.reshape(stb.shape[0],-1).cuda())\n",
    "                a, _ = actor(stb.reshape(stb.shape[0],-1).cuda())\n",
    "                V.append(v)\n",
    "                A.append(a)\n",
    "            V = torch.concat(V,0)\n",
    "            A = torch.concat(A,0)\n",
    "\n",
    "            V_t = []\n",
    "            for b in range((len(st)+batch_size-1)//batch_size):\n",
    "                stb = st[b*batch_size:(b+1)*batch_size]\n",
    "\n",
    "                _, v = target_critic(stb.reshape(stb.shape[0],-1).cuda())\n",
    "\n",
    "                V_t.append(v)\n",
    "            V_t = torch.concat(V_t,0)\n",
    "\n",
    "\n",
    "            if use_symlog:\n",
    "                V = (V.softmax(1)@bin_values[:,None])[:,0].detach().cpu()\n",
    "                V_t = (V_t.softmax(1)@bin_values[:,None])[:,0].detach().cpu()\n",
    "            else:\n",
    "                V = V.cpu()\n",
    "                V_t = V_t.cpu()\n",
    "\n",
    "            tb_writer.add_image('V', (V.reshape(1,100,100)/2+0.5), i)\n",
    "            tb_writer.add_image('V_t', V_t.reshape(1,100,100)/2+0.5, i)\n",
    "\n",
    "            plotV.append(V.reshape(1,100,100).detach().cpu())\n",
    "            plotVT.append(V_t.reshape(1,100,100).detach().cpu())\n",
    "\n",
    "            pos = st[:,0].reshape(100,100,-1)[::2,::2]\n",
    "            A = A.reshape(100,100,-1)[::2,::2]\n",
    "            # A = A/2\n",
    "            action_probs = A.softmax(-1)\n",
    "            u = action_probs@dec_x[:,None]\n",
    "            v = action_probs@dec_y[:,None]\n",
    "            A = torch.concat([u,v],-1)\n",
    "\n",
    "            plt.quiver(pos[...,1].flatten(), -pos[...,0].flatten(), A[...,1].tanh().detach().cpu().flatten(), -A[...,0].tanh().detach().cpu().flatten(), color='g',scale=50, headwidth=2)\n",
    "            ax.axis('off')\n",
    "            plt.gca().set_aspect('equal')\n",
    "            plt.subplots_adjust(0,0,1,1,0,0)\n",
    "            fig.canvas.draw()\n",
    "            data = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "            data = data.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "            plt.clf()\n",
    "\n",
    "            tb_writer.add_image('Policy visualization', np.transpose(data,(2,0,1)) , i)\n",
    "            plotPolicy.append(np.transpose(data,(2,0,1)))\n",
    "\n",
    "    # experiment.update({'E':torch.tensor(E), 'plotV':torch.stack(plotV), 'plotVT':torch.stack(plotVT), 'plotPolicy':torch.tensor(plotPolicy)})\n",
    "    torch.save(experiment,\n",
    "        os.path.join(log_dir,'results.pth'))\n",
    "\n",
    "\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6005.871283,
   "end_time": "2023-07-10T11:03:09.346626",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-10T09:23:03.475343",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
